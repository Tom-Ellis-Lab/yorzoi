{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86e6457-ecc6-48d5-bafc-6169f1131550",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed274415-2813-4a9c-8a13-da3e41a4e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import glob\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2fc1b0-fed9-452a-aec7-aa875102b5ae",
   "metadata": {},
   "source": [
    "# read test data and corresponding expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddf0258-5b39-42eb-b1e6-8fafdca3227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71103\n",
      "1.65983547290171\n",
      "-1.40175772469441\n"
     ]
    }
   ],
   "source": [
    "filename = 'filtered_test_data_with_MAUDE_expression.txt'\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    lines = list(reader)\n",
    "\n",
    "filtered_tagged_sequences = [line[0] for line in lines]\n",
    "expressions = [line[1] for line in lines]\n",
    "\n",
    "GROUND_TRUTH_EXP = np.array([float(expressions[i]) for i in range(len(filtered_tagged_sequences))])\n",
    "print(len(GROUND_TRUTH_EXP))\n",
    "\n",
    "print(max(GROUND_TRUTH_EXP))\n",
    "print(min(GROUND_TRUTH_EXP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d746e-cf42-4804-91bf-d7811d51c8f0",
   "metadata": {},
   "source": [
    "# read different promoter classes ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ce2e75-7b5d-47b9-b04d-4f0f795c0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_subset_ids/high_exp_seqs.csv')\n",
    "high = list(df['pos'])\n",
    "high = np.unique(np.array(high))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/low_exp_seqs.csv')\n",
    "low = list(df['pos'])\n",
    "low = np.unique(np.array(low))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/yeast_seqs.csv')\n",
    "yeast = list(df['pos'])\n",
    "yeast = np.unique(np.array(yeast))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/all_random_seqs.csv')\n",
    "random = list(df['pos'])\n",
    "random = np.unique(np.array(random))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/challenging_seqs.csv')\n",
    "challenging = list(df['pos'])\n",
    "challenging = np.unique(np.array(challenging))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/all_SNVs_seqs.csv')\n",
    "SNVs_alt = list(df['alt_pos'])\n",
    "SNVs_ref = list(df['ref_pos'])\n",
    "SNVs = list(set(list(zip(SNVs_alt, SNVs_ref))))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/motif_perturbation.csv')\n",
    "motif_perturbation_alt = list(df['alt_pos'])\n",
    "motif_perturbation_ref = list(df['ref_pos'])\n",
    "motif_perturbation = list(set(list(zip(motif_perturbation_alt, motif_perturbation_ref))))\n",
    "\n",
    "df = pd.read_csv('test_subset_ids/motif_tiling_seqs.csv')\n",
    "motif_tiling_alt = list(df['alt_pos'])\n",
    "motif_tiling_ref = list(df['ref_pos'])\n",
    "motif_tiling = list(set(list(zip(motif_tiling_alt, motif_tiling_ref))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44beb6c6-edc2-48cf-b1e8-6ba44a29b746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968\n",
      "997\n",
      "578\n",
      "6349\n",
      "1953\n",
      "3287\n",
      "2624\n",
      "44340\n"
     ]
    }
   ],
   "source": [
    "print(len(high))\n",
    "print(len(low))\n",
    "print(len(yeast))\n",
    "print(len(random))\n",
    "print(len(challenging))\n",
    "print(len(motif_perturbation))\n",
    "print(len(motif_tiling))\n",
    "print(len(SNVs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671a83f-bad5-46fa-bdbd-23b27d577d79",
   "metadata": {},
   "source": [
    "# Get the different promoter class ids used in the public leaderboard of the DREAM challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e8b585-9e8d-47a9-8f31-d140a7a131ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('public_leaderboard_ids/high_exp_indices.json', 'r') as f:\n",
    "    public_high = [int(indice) for indice in list(json.load(f).keys())]\n",
    "\n",
    "with open('public_leaderboard_ids/low_exp_indices.json', 'r') as f:\n",
    "    public_low = [int(indice) for indice in list(json.load(f).keys())]\n",
    "\n",
    "with open('public_leaderboard_ids/yeast_exp_indices.json', 'r') as f:\n",
    "    public_yeast = [int(indice) for indice in list(json.load(f).keys())]\n",
    "\n",
    "with open('public_leaderboard_ids/random_exp_indices.json', 'r') as f:\n",
    "    public_random = [int(indice) for indice in list(json.load(f).keys())]\n",
    "\n",
    "with open('public_leaderboard_ids/challenging_exp_indices.json', 'r') as f:\n",
    "    public_challenging = [int(indice) for indice in list(json.load(f).keys())]\n",
    "    \n",
    "with open('public_leaderboard_ids/SNVs_exp_indices.json', 'r') as f:\n",
    "    public_SNVs = [(int(indice.split(',')[0]), int(indice.split(',')[1])) for indice in list(json.load(f).keys())]\n",
    "\n",
    "with open('public_leaderboard_ids/motif_perturbation_exp_indices.json', 'r') as f:\n",
    "    public_motif_perturbation = [(int(indice.split(',')[0]), int(indice.split(',')[1])) for indice in list(json.load(f).keys())]\n",
    "\n",
    "with open('public_leaderboard_ids/motif_tiling_exp_indices.json', 'r') as f:\n",
    "    public_motif_tiling = [(int(indice.split(',')[0]), int(indice.split(',')[1])) for indice in list(json.load(f).keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f21f2c-2a63-4e5f-9c7d-1e630365320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "99\n",
      "208\n",
      "733\n",
      "195\n",
      "4670\n",
      "328\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "print(len(public_high))\n",
    "print(len(public_low))\n",
    "print(len(public_yeast))\n",
    "print(len(public_random))\n",
    "print(len(public_challenging))\n",
    "print(len(public_SNVs))\n",
    "print(len(public_motif_perturbation))\n",
    "print(len(public_motif_tiling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75737104-da85-4af7-855d-60f880667cd2",
   "metadata": {},
   "source": [
    "# Get the final test dataset used for private evaluation in the DREAM Chalenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e45364-933e-4cbf-b3eb-4bc067b05461",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_single_indices = public_high + public_low + public_yeast + public_random + public_challenging\n",
    "public_double_indices = public_SNVs + public_motif_perturbation + public_motif_tiling\n",
    "\n",
    "public_indices = []\n",
    "\n",
    "for indice in public_double_indices:\n",
    "    public_indices.append(indice[0])\n",
    "    public_indices.append(indice[1])\n",
    "\n",
    "for indice in public_single_indices:\n",
    "    public_indices.append(indice)\n",
    "\n",
    "public_indices = list(set(public_indices))\n",
    "\n",
    "final_high = [exp for exp in high if exp not in public_indices]\n",
    "final_low = [exp for exp in low if exp not in public_indices]\n",
    "final_yeast = [exp for exp in yeast if exp not in public_indices]\n",
    "final_random = [exp for exp in random if exp not in public_indices]\n",
    "final_challenging = [exp for exp in challenging if exp not in public_indices]\n",
    "final_SNVs = [exp for exp in SNVs if exp not in public_double_indices]\n",
    "final_motif_perturbation = [exp for exp in motif_perturbation if exp not in public_double_indices]\n",
    "final_motif_tiling = [exp for exp in motif_tiling if exp not in public_double_indices]\n",
    "final_all = [exp for exp in list(range(len(GROUND_TRUTH_EXP))) if exp not in public_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fc7341-6099-4092-b0e6-300e62f4f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "898\n",
      "370\n",
      "5616\n",
      "1758\n",
      "39904\n",
      "2959\n",
      "2361\n",
      "62058\n"
     ]
    }
   ],
   "source": [
    "print(len(final_high))\n",
    "print(len(final_low))\n",
    "print(len(final_yeast))\n",
    "print(len(final_random))\n",
    "print(len(final_challenging))\n",
    "print(len(final_SNVs))\n",
    "print(len(final_motif_perturbation))\n",
    "print(len(final_motif_tiling))\n",
    "print(len(final_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8f1074-1031-4081-9278-6b63981679d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39904"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(final_SNVs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30eca67-171c-4dbd-aa19-1ce582ca02d8",
   "metadata": {},
   "source": [
    "# Performance on final test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7865b6-3d32-420d-af66-c5dc2dd99c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations(index_list, expressions, GROUND_TRUTH_EXP):\n",
    "    PRED_DATA = OrderedDict()\n",
    "    GROUND_TRUTH = OrderedDict()\n",
    "\n",
    "    for j in index_list:\n",
    "        PRED_DATA[str(j)] = float(expressions[j])\n",
    "        GROUND_TRUTH[str(j)] = float(GROUND_TRUTH_EXP[j])\n",
    "\n",
    "    pearson = pearsonr(list(GROUND_TRUTH.values()), list(PRED_DATA.values()))[0]\n",
    "    spearman = spearmanr(list(GROUND_TRUTH.values()), list(PRED_DATA.values()))[0]\n",
    "\n",
    "    return pearson, spearman\n",
    "\n",
    "\n",
    "def calculate_diff_correlations(pair_list, expressions, GROUND_TRUTH_EXP):\n",
    "    Y_pred_selected = []\n",
    "    expressions_selected = []\n",
    "\n",
    "    for pair in pair_list:\n",
    "        ref, alt = pair[0], pair[1]\n",
    "        Y_pred_selected.append(expressions[alt] - expressions[ref])\n",
    "        expressions_selected.append(GROUND_TRUTH_EXP[alt] - GROUND_TRUTH_EXP[ref])\n",
    "\n",
    "    Y_pred_selected = np.array(Y_pred_selected)\n",
    "    expressions_selected = np.array(expressions_selected)\n",
    "\n",
    "    pearson = pearsonr(expressions_selected, Y_pred_selected)[0]\n",
    "    spearman = spearmanr(expressions_selected, Y_pred_selected)[0]\n",
    "\n",
    "    return pearson, spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959b48c7-e7f4-4a02-a222-21da13fb6a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reference model predictions.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m expressions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference model predictions.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lines)):\n",
      "File \u001b[0;32m/home/workspace/clex/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reference model predictions.txt'"
     ]
    }
   ],
   "source": [
    "# Read expressions\n",
    "sequences = []\n",
    "expressions = []\n",
    "filename = 'reference model predictions.txt'\n",
    "\n",
    "with open(filename) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for j in range(len(lines)):\n",
    "    exp = lines[j].split('\\t')[1].split('\\n')[0]\n",
    "    expressions.append(float(exp))\n",
    "\n",
    "expressions = np.array(expressions)\n",
    "\n",
    "# Calculate correlations\n",
    "pearson, spearman = calculate_correlations(final_all, expressions, GROUND_TRUTH_EXP)\n",
    "high_pearson, high_spearman = calculate_correlations(final_high, expressions, GROUND_TRUTH_EXP)\n",
    "low_pearson, low_spearman = calculate_correlations(final_low, expressions, GROUND_TRUTH_EXP)\n",
    "yeast_pearson, yeast_spearman = calculate_correlations(final_yeast, expressions, GROUND_TRUTH_EXP)\n",
    "random_pearson, random_spearman = calculate_correlations(final_random, expressions, GROUND_TRUTH_EXP)\n",
    "challenging_pearson, challenging_spearman = calculate_correlations(final_challenging, expressions, GROUND_TRUTH_EXP)\n",
    "\n",
    "# Calculate difference correlations\n",
    "SNVs_pearson, SNVs_spearman = calculate_diff_correlations(final_SNVs, expressions, GROUND_TRUTH_EXP)\n",
    "motif_perturbation_pearson, motif_perturbation_spearman = calculate_diff_correlations(final_motif_perturbation, expressions, GROUND_TRUTH_EXP)\n",
    "motif_tiling_pearson, motif_tiling_spearman = calculate_diff_correlations(final_motif_tiling, expressions, GROUND_TRUTH_EXP)\n",
    "\n",
    "\n",
    "# Calculate scores\n",
    "pearsons_score = (pearson**2 + 0.3 * high_pearson**2 + 0.3 * low_pearson**2 + 0.3 * yeast_pearson**2 + \n",
    "                  0.3 * random_pearson**2 + 0.5 * challenging_pearson**2 + 1.25 * SNVs_pearson**2 + \n",
    "                  0.3 * motif_perturbation_pearson**2 + 0.4 * motif_tiling_pearson**2) / 4.65\n",
    "\n",
    "\n",
    "spearmans_score = (spearman + 0.3 * high_spearman + 0.3 * low_spearman + 0.3 * yeast_spearman \n",
    "                   + 0.3 * random_spearman + 0.5 * challenging_spearman + 1.25 * SNVs_spearman\n",
    "                   + 0.3 * motif_perturbation_spearman + 0.4 * motif_tiling_spearman) / 4.65\n",
    "\n",
    "# Print scores\n",
    "print('******************************************************')\n",
    "print('Pearson Score: {}\\n'.format(pearsons_score))\n",
    "print('Spearman Score: {}\\n'.format(spearmans_score))\n",
    "print('******************************************************')\n",
    "print('all r: {}\\n'.format(pearson))\n",
    "print('all r\\u00b2: {}\\n'.format(pearson**2))\n",
    "print('all \\u03C1: {}\\n'.format(spearman))\n",
    "print('******************************************************')\n",
    "print('high r: {}\\n'.format(high_pearson))\n",
    "print('low r: {}\\n'.format(low_pearson))\n",
    "print('yeast r: {}\\n'.format(yeast_pearson))\n",
    "print('random r: {}\\n'.format(random_pearson))\n",
    "print('challenging r: {}\\n'.format(challenging_pearson))\n",
    "print('SNVs r: {}\\n'.format(SNVs_pearson))\n",
    "print('motif perturbation r: {}\\n'.format(motif_perturbation_pearson))\n",
    "print('motif tiling r: {}\\n'.format(motif_tiling_pearson))\n",
    "print('******************************************************')\n",
    "print('high \\u03C1: {}\\n'.format(high_spearman))\n",
    "print('low \\u03C1: {}\\n'.format(low_spearman))\n",
    "print('yeast \\u03C1: {}\\n'.format(yeast_spearman))\n",
    "print('random \\u03C1: {}\\n'.format(random_spearman))\n",
    "print('challenging \\u03C1: {}\\n'.format(challenging_spearman))\n",
    "print('SNVs \\u03C1: {}\\n'.format(SNVs_spearman))\n",
    "print('motif perturbation \\u03C1: {}\\n'.format(motif_perturbation_spearman))\n",
    "print('motif tiling \\u03C1: {}\\n'.format(motif_tiling_spearman))\n",
    "print('******************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcda13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
